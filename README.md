# â¤ï¸ Japan Heart Attack Prediction ğŸ¥

Welcome to the **Japan Heart Attack Prediction** project! This project aims to predict the risk of heart attack using machine learning models trained on a dataset from Japan. The project includes data preprocessing, model training, and deployment using Docker, Amazon S3, ECR, EC2, and MongoDB.

project link : [JAPAN HEART ATTACK](https://japanheartattack.streamlit.app/).

---

## ğŸ“‚ Directory Structure

Hereâ€™s the structure of the project:
<details> <summary>Click to expand/collapse directory structure</summary>

```
â””â”€â”€ de5hpande-japan_heart_attack/
    â”œâ”€â”€ Dockerfile
    â”œâ”€â”€ app.py
    â”œâ”€â”€ check_mongodb.py
    â”œâ”€â”€ main.py
    â”œâ”€â”€ push_data.py
    â”œâ”€â”€ requirements.txt
    â”œâ”€â”€ setup.py
    â”œâ”€â”€ data/
    â”‚   â”œâ”€â”€ combined_dataset.csv
    â”‚   â”œâ”€â”€ heart_attack_risk_dataset.csv
    â”‚   â”œâ”€â”€ japan_dataset.csv
    â”‚   â”œâ”€â”€ japan_final_ha.csv
    â”‚   â”œâ”€â”€ japan_heart_attack_dataset.csv
    â”‚   â”œâ”€â”€ test.ipynb
    â”‚   â””â”€â”€ unbalnced.ipynb
    â”œâ”€â”€ data_schema/
    â”‚   â””â”€â”€ schema.yaml
    â”œâ”€â”€ japan_ha/
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ __pycache__/
    â”‚   â”œâ”€â”€ cloud/
    â”‚   â”‚   â””â”€â”€ __init__.py
    â”‚   â”œâ”€â”€ components/
    â”‚   â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”‚   â”œâ”€â”€ data_ingestion.py
    â”‚   â”‚   â”œâ”€â”€ data_transformation.py
    â”‚   â”‚   â”œâ”€â”€ data_validation.py
    â”‚   â”‚   â”œâ”€â”€ model_trainer.py
    â”‚   â”‚   â””â”€â”€ __pycache__/
    â”‚   â”œâ”€â”€ constant/
    â”‚   â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”‚   â”œâ”€â”€ __pycache__/
    â”‚   â”‚   â””â”€â”€ training_pipeline/
    â”‚   â”‚       â”œâ”€â”€ __init__.py
    â”‚   â”‚       â””â”€â”€ __pycache__/
    â”‚   â”œâ”€â”€ entity/
    â”‚   â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”‚   â”œâ”€â”€ artifacts_entity.py
    â”‚   â”‚   â”œâ”€â”€ config_entity.py
    â”‚   â”‚   â””â”€â”€ __pycache__/
    â”‚   â”œâ”€â”€ exception/
    â”‚   â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”‚   â”œâ”€â”€ exception.py
    â”‚   â”‚   â””â”€â”€ __pycache__/
    â”‚   â”œâ”€â”€ logging/
    â”‚   â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”‚   â”œâ”€â”€ logger.py
    â”‚   â”‚   â””â”€â”€ __pycache__/
    â”‚   â”œâ”€â”€ pipeline/
    â”‚   â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”‚   â”œâ”€â”€ batch_prediction.py
    â”‚   â”‚   â”œâ”€â”€ training_pipeline.py
    â”‚   â”‚   â””â”€â”€ __pycache__/
    â”‚   â””â”€â”€ utils/
    â”‚       â”œâ”€â”€ __init__.py
    â”‚       â”œâ”€â”€ __pycache__/
    â”‚       â”œâ”€â”€ main_utils/
    â”‚       â”‚   â”œâ”€â”€ __init__.py
    â”‚       â”‚   â”œâ”€â”€ utils.py
    â”‚       â”‚   â””â”€â”€ __pycache__/
    â”‚       â””â”€â”€ ml_utils/
    â”‚           â”œâ”€â”€ __init__.py
    â”‚           â”œâ”€â”€ __pycache__/
    â”‚           â”œâ”€â”€ metric/
    â”‚           â”‚   â”œâ”€â”€ __init__.py
    â”‚           â”‚   â”œâ”€â”€ classification_matrics.py
    â”‚           â”‚   â””â”€â”€ __pycache__/
    â”‚           â””â”€â”€ model/
    â”‚               â”œâ”€â”€ __init__.py
    â”‚               â”œâ”€â”€ estimator.py
    â”‚               â””â”€â”€ __pycache__/
    â”œâ”€â”€ notebook/
    â”‚   â”œâ”€â”€ EDAandMODELTraining.ipynb
    â”‚   â””â”€â”€ japan_heart_attack_dataset.csv
    â”œâ”€â”€ templates/
    â”‚   â””â”€â”€ table.html
    â””â”€â”€ valid_data/
        â””â”€â”€ test.csv
```
</details>
---

## ğŸš€ Features

- **Data Ingestion**: Fetch data from MongoDB for training.
- **Data Preprocessing**: Handle missing values, encode categorical features, and scale numerical features.
- **Imbalanced Data Handling**: Use **SMOTE** to balance the dataset.
- **Model Training**: Train machine learning models using the preprocessed data.
- **Model Deployment**: Deploy the model using **Docker**, **Amazon ECR**, and **EC2**.
- **Streamlit App**: A beautiful and interactive web app for predictions.

---

## ğŸ› ï¸ Technologies Used

- **Python**: Primary programming language.
- **Pandas & NumPy**: Data manipulation and analysis.
- **Scikit-learn**: Machine learning models and preprocessing.
- **MongoDB**: Database for storing and retrieving data.
- **Docker**: Containerization for deployment.
- **Amazon S3**: Storage for datasets and model artifacts.
- **Amazon ECR & EC2**: Deployment and hosting.
- **Streamlit**: Web app for user interaction.

---

## ğŸ“Š Dataset

The dataset contains health-related features such as:
- **Age**, **Cholesterol Level**, **BMI**, **Heart Rate**, **Blood Pressure**, etc.
- **Categorical Features**: Gender, Smoking History, Diabetes History, etc.

The dataset is stored in MongoDB and preprocessed using **SMOTE** to handle class imbalance.

---

## ğŸ³ Docker Deployment

The project is containerized using Docker. Hereâ€™s how to build and run the Docker image:

```bash
# Build the Docker image
docker build -t japan_heart_attack .

# Run the Docker container
docker run -p 8501:8501 japan_heart_attack
```

---

## â˜ï¸ Cloud Deployment

The model is deployed on **Amazon Web Services (AWS)**:
- **Amazon S3**: Used to store datasets and model artifacts. [Add S3 Link Here]
- **Amazon ECR**: Docker images are pushed to ECR. [Add ECR Link Here]
- **Amazon EC2**: The app is hosted on an EC2 instance. [Add EC2 Link Here]

---

## ğŸ“ How to Run Locally

### **Step 1: Set Up the Environment**

1. Create a virtual environment using `conda`:
   ```bash
   conda create -n venv python=3.8
   conda activate venv/
   ```

2. Install the required packages:
   ```bash
   pip install -r requirements.txt
   ```

### **Step 2: Run the Streamlit App**

1. Start the Streamlit app:
   ```bash
   streamlit run streamlit_app.py
   ```

2. Open your browser and go to `http://localhost:8501`.

---

## ğŸ“¸ Proof of Work

Here are some screenshots of the project in action:

- **Streamlit App**: [Add Screenshot Link Here]
- **Docker Build**: [Add Screenshot Link Here]
- **AWS Deployment**: [Add Screenshot Link Here]

---

## ğŸ™ Acknowledgments

- Thanks to the creators of the dataset.
- Special thanks to the open-source community for their amazing tools and libraries.

---

Made with â¤ï¸ by [**Rishabh Deshpande**].  
ğŸ“§ Contact: [rishabhmse@gmail.com]  
ğŸ”— GitHub: [https://github.com/de5hpande]

---